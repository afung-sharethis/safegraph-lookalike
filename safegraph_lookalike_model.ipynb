{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safegraph Lookalike Model\n",
    "\n",
    "This notebook implements the Cosine Medoid Lookalike Model to predict a user's interest in an offline brand.\n",
    "\n",
    "Ideal users that have visited a specific offline brand will be used to find a \"golden seed\" (the cosine-medoid). We compare users to this golden seed by computing their cosine-similarity, and accepting similarity scores above a pre-defined percentile threshold\n",
    "\n",
    "To use this notebook, edit the cells in the `Resluts` and `Experiments` sections\n",
    "\n",
    "#### Outputs (see results/experiments section below):\n",
    "- Lookalike Model classification plot: `plotly_results/{filename}.html`\n",
    "- Center distribution experiment plot: `plotly_results/{center_fn}.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Install necessary packages\n",
    "# Convert to raw cell when not using to prevent redundant computation and spam\n",
    "\n",
    "!pip3 install -U scikit-learn scikit-learn-extra\n",
    "!pip3 install -U matplotlib pandas numpy plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQODAAFbisVI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from math import floor\n",
    "import pickle\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\" Pre-process text data in the given DF's\n",
    "    \n",
    "    Processing:\n",
    "        - keywords from Watson are linked by \"_\", convert these to spaces\n",
    "        - lowercase all text\n",
    "    \"\"\"\n",
    "    data.loc[:,'keywords'] = data['keywords'].str.replace(\"_\", \" \")\n",
    "    data = data.apply((lambda x: x.str.lower() if x.name in ['domains','titles','keywords'] else x), axis=0)\n",
    "    return data\n",
    "\n",
    "def label_embeddings(emb, labels, group, num_embeddings=None):\n",
    "    \"\"\" Add text labels to an embeddings DF \"\"\"\n",
    "    num_embed = emb.shape[0] if num_embeddings is None else num_embeddings\n",
    "    num_feats = emb.shape[1]\n",
    "    df = pd.DataFrame(emb, columns = [\"dim\"+str(i) for i in range(num_feats)])\n",
    "    df[\"titles\"] = labels.loc[:num_embed, \"titles\"]\n",
    "    df[\"keywords\"] = labels.loc[:num_embed, \"keywords\"]\n",
    "    df[\"brands\"] = labels.loc[:num_embed, \"brands\"]\n",
    "    df[\"group\"] = group\n",
    "    return df\n",
    "\n",
    "def centroid_to_dataframe(centroid, labels, idx):\n",
    "    \"\"\" Create a dummy 1-row DF for the centroid for easy concatenation later on \"\"\"\n",
    "    df = pd.DataFrame(centroid, columns = [\"dim\"+str(i) for i in range(num_feats)])\n",
    "    df[\"titles\"] = labels.loc[idx, \"titles\"]\n",
    "    df[\"keywords\"] = labels.loc[idx, \"keywords\"]\n",
    "    df[\"brands\"] = labels.loc[idx, \"brands\"]\n",
    "    df[\"group\"] = \"centroid\"\n",
    "    return df\n",
    "\n",
    "def add_hover_text(df, char_lim=500):\n",
    "    \"\"\" Crop and wrap text to render as plotly labels \"\"\"\n",
    "    replace_endl = lambda s: s.replace('\\n', '<br>')\n",
    "    df['hover'] = \"Cosine Similarity: \" + df['cos_sim'].astype(str) + \\\n",
    "        \"<br><br>Keywords: \" + df['keywords'].astype(str).str[:char_lim].str.wrap(75).apply(replace_endl) + \\\n",
    "        \"<br><br>Titles: \" + df['titles'].astype(str).str[:char_lim].str.wrap(75).apply(replace_endl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Lookalike Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6E6yk6fisVV"
   },
   "outputs": [],
   "source": [
    "def cos_sim(a,b):\n",
    "    return (a@b/(la.norm(a)*la.norm(b)))[0]\n",
    "\n",
    "def euc_dist(a,b):\n",
    "    return la.norm(a-b)\n",
    "\n",
    "def compute_center_kmedoids(data):\n",
    "    \"\"\" Use KMeoids with 1 cluster to compute the center \"\"\"\n",
    "    model = KMedoids(metric=\"cosine\", n_clusters=1)\n",
    "    model.fit(data)\n",
    "    centroids = model.cluster_centers_\n",
    "    idx = model.medoid_indices_[0]\n",
    "    return centroids, idx\n",
    "\n",
    "def compute_center(data):\n",
    "    \"\"\" Directly compute the medoid of the set \"\"\"\n",
    "    pw = pairwise_distances(data, metric='cosine')\n",
    "    totals = np.sum(pw, axis=0)\n",
    "    idx = np.argmin(totals)\n",
    "    return np.expand_dims(data[idx], axis=0), idx\n",
    "    \n",
    "def add_prediction(data, centroid, num_feats, percentile):\n",
    "    \"\"\" Compute cosine similarity and pos/neg predictions, add these as columns to the DF \"\"\"\n",
    "    data[\"cos_sim\"] = data.apply(lambda row: cos_sim(centroid, np.array([row['dim{}'.format(str(i))] for i in range(num_feats)])), axis=1)\n",
    "    data.sort_values(by = \"cos_sim\", ascending = False, inplace=True)\n",
    "    \n",
    "    threshold = np.percentile(data['cos_sim'].values, percentile)\n",
    "    data[\"pred\"] = data.apply(lambda row: \"positive\" if row[\"cos_sim\"] >= threshold else \"negative\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeO5xxvkisVi"
   },
   "outputs": [],
   "source": [
    "def pred_interpretation(data, main_group):\n",
    "    \"\"\" Print accuracy, precision, and recall analysis \"\"\"\n",
    "    TP = len(data[(data['pred'] == \"positive\") & (data['group'] == main_group)])\n",
    "    TN = len(data[(data['pred'] != \"positive\") & (data['group'] != main_group)])\n",
    "    FP = len(data[(data['pred'] == \"positive\") & (data['group'] != main_group)])\n",
    "    FN = len(data[(data['pred'] != \"positive\") & (data['group'] == main_group)])\n",
    "\n",
    "    accuracy = (TP + TN)/(TP + TN + FP + FN) * 100\n",
    "    precision = TP / (TP + FP) * 100\n",
    "    recall = TP / (TP + FN) * 100\n",
    "    print('FN={}, TN={}, TP={}, FP={}'.format(FN,TN,TP,FP))\n",
    "    print(\"We have an accuracy={:.0f}%, precision={:.0f}% and recall={:.0f}% \".format(accuracy, precision, recall))\n",
    "    \n",
    "def dim_reduce(data):\n",
    "    \"\"\" Reduce labelled input to 2 dimensions \"\"\"\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "    # TODO: take only embeddings as input and move label-dropping outside this function\n",
    "    x = data.drop(axis=1, columns=[\"group\",\"titles\",\"keywords\",\"cos_sim\",\"pred\",\"brands\"]).values\n",
    "\n",
    "    tsneComponents = tsne.fit_transform(x)\n",
    "    principalDf = pd.DataFrame(data = tsneComponents\n",
    "              , columns = ['component 1', 'component 2'])\n",
    "    finalDf = pd.concat([principalDf, data[['titles','keywords','brands','group','cos_sim','pred']].reset_index()], axis = 1)\n",
    "    return finalDf\n",
    "\n",
    "def split_preds(df, main_group, comp_group):\n",
    "    \"\"\" Split predictions into true/false positive/negative \"\"\"\n",
    "    fp = df[(df['pred'] == 'positive') & (df['group'] == comp_group)]\n",
    "    tn = df[(df['pred'] == 'negative') & (df['group'] == comp_group)]\n",
    "    tp = df[(df['pred'] == 'positive') & (df['group'] == main_group)]\n",
    "    fn = df[(df['pred'] == 'negative') & (df['group'] == main_group)]\n",
    "    center = df[df['group'] == 'centroid']\n",
    "    return tn, fp, tp, fn, center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model(main_data, comp_data, main_group, comp_group, percentile):\n",
    "    \"\"\" Compute a center and lookalike predictions\n",
    "    \n",
    "    :return: Returns the following 3-tuple\n",
    "        - A DF of all embeddings (including the center) reduced to 2 dimensions\n",
    "        - The computed center as a DF\n",
    "        - The fully labelled embeddings DF with cos-sim and predictions\n",
    "    \"\"\"\n",
    "    train, test = train_test_split(main_data, test_size=0.3)\n",
    "    \n",
    "    # Compute Center\n",
    "    X_train = train.drop(axis=1, columns=[\"group\",\"titles\",\"keywords\",\"brands\"]).values\n",
    "    center, idx = compute_center(X_train)\n",
    "    center_data = centroid_to_dataframe(center, train.reset_index(), idx)\n",
    "    \n",
    "    # Create lookalike model\n",
    "    predDf = pd.concat([comp_data, test, center_data])\n",
    "    add_prediction(predDf, center, num_feats, percentile)\n",
    "\n",
    "    return dim_reduce(predDf), center_data, predDf        # Reduce and return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GpeL9ld7isWF",
    "outputId": "704c97ad-b308-44fe-85ff-2acae8836772"
   },
   "outputs": [],
   "source": [
    "def plot_figure(filename, main_group, comp_group, TN, FP, TP, FN, center_pred):\n",
    "    \"\"\" Visualize lookalike model classification \n",
    "    \n",
    "    :returns: A plotly figure to be saved and rendered\n",
    "    \"\"\"\n",
    "    targets = [TN, FP, TP, FN]\n",
    "    names = [comp_group+' negative', comp_group+' positive', main_group+' positive', main_group+' negative']\n",
    "    colors = ['red', 'blue', 'green', 'pink']\n",
    "\n",
    "    xy=[]\n",
    "\n",
    "    # Plot provided embeddings\n",
    "    for target, color, name in zip(targets, colors, names):\n",
    "        xy.append(go.Scatter(x=target['component 1']\n",
    "                , y=target['component 2']\n",
    "                , mode='markers'\n",
    "                , marker=dict(size=5, color=color)\n",
    "                , name=name\n",
    "                , hovertext=target['hover']))\n",
    "\n",
    "    # Plot center\n",
    "    xy.append(go.Scatter(\n",
    "          mode = 'markers',\n",
    "          x = center_pred['component 1'],\n",
    "          y = center_pred['component 2'],\n",
    "          name = \"Center\",\n",
    "          hovertext=center_pred['hover'],\n",
    "          marker = dict(\n",
    "            color = 'orange',\n",
    "            size = 20,\n",
    "            symbol = 'x-dot')))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title= \"2 components TSNE\",\n",
    "        hovermode='closest',\n",
    "        xaxis=dict(title='component 1', ticklen=5, zeroline=False, gridwidth=2),\n",
    "        yaxis=dict( title='component 2', ticklen=5, gridwidth=2),\n",
    "        width=1000,\n",
    "        height=1000)\n",
    "    return go.Figure(data=xy, layout=layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTlO5rrHisV4"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Label Data\n",
    "\n",
    "This is usually the only cell you will need to edit. Simply change the variables within this cell to fit your job, and then run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-2upDE7isVk"
   },
   "outputs": [],
   "source": [
    "# Names and groups\n",
    "main_group = 'gamestop'\n",
    "comp_group = 'full_merge'\n",
    "filename = 'all_brands_gamestop_strict_SBERT-post'\n",
    "\n",
    "# Label dataframes\n",
    "main_label = pd.read_csv(\"data/safegraph/merge_brands/safegraph_gamestop_raw.csv\").dropna().head(2000)\n",
    "comp_label = pd.read_csv(\"data/safegraph/merge_brands/safegraph_full_merge_ndomain7.csv\").dropna()\n",
    "main_label[\"brands\"] = \"Gamestop\"\n",
    "comp_label[\"brands\"] = \"N/A\"\n",
    "\n",
    "main_label =  preprocess(main_label)\n",
    "comp_label =  preprocess(comp_label)\n",
    "\n",
    "# Embeddings dataframes\n",
    "main_emb = np.load('npy_pickles/gamestop_raw_2000_SBERT.npy')\n",
    "comp_emb = np.load('npy_pickles/full_merge_SBERT.npy')\n",
    "assert(main_emb.shape[1] == comp_emb.shape[1])\n",
    "num_feats = main_emb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymxs7rdfisVm"
   },
   "outputs": [],
   "source": [
    "# Combine embeddings, labels, and names\n",
    "main_data = label_embeddings(main_emb, main_label, main_group)\n",
    "comp_data = label_embeddings(comp_emb, comp_label, comp_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Lookalike Model for the brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFqQJ3PGisVt"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# filename = 'all_brands_gamestop_strict_euc'\n",
    "redDf, centerDf, predDf = gen_model(main_data, comp_data, main_group, comp_group, 60)\n",
    "pred_interpretation(predDf, main_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Lookalike Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_hover_text(redDf)\n",
    "split = split_preds(redDf, main_group, comp_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_figure(filename, main_group, comp_group, *split)\n",
    "fig.write_html(\"plotly_results/{0}.html\".format(filename))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMISzDcp0DhX"
   },
   "source": [
    "# Experiments\n",
    "\n",
    "This section details further investigations taken to analyze the proposed lookalike model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center Distribution\n",
    "\n",
    "We generate 1000 different train/test splits and plot the centers computed from the training sets. We observe from the resulting graph that there are many repeated centers, showing good precision.\n",
    "\n",
    "**Problem:** Not all of the most common centers may be very related to the brand, so we should find a way to retain only the centers that we deem relevant. Since generating the \"Golden Seed\" should be a one-time task (or at least a few-time task) then we can just have a human examine the centers generated from this experiment and select the best-fitting ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and label centers\n",
    "\n",
    "May need to change filename, otherwise data is loaded above. It may be better to move the filename variable to another cell to keep track of it easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "center_fn = \"centroids_SBERT-post\"\n",
    "\n",
    "# Start with all data points, and merge the new centers together with the original data\n",
    "dfs = [main_data]\n",
    "\n",
    "N = 1000\n",
    "for i in range(N):\n",
    "    train, test = train_test_split(main_data, test_size=0.3)\n",
    "    \n",
    "    # Compute Center\n",
    "    X_train = train.drop(axis=1, columns=[\"group\",\"titles\",\"keywords\",\"brands\"]).values\n",
    "    center, idx = compute_center(X_train)\n",
    "    center_data = centroid_to_dataframe(center, train.reset_index(), idx)\n",
    "    dfs.append(center_data)\n",
    "\n",
    "# Merge all data points into a single DF and add dummy labels\n",
    "mergedDf = pd.concat(dfs)\n",
    "mergedDf['cos_sim'] = 0\n",
    "mergedDf['pred'] = 'n/a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "reducedDf = dim_reduce(mergedDf)\n",
    "add_hover_text(reducedDf)\n",
    "\n",
    "main = reducedDf[reducedDf['group'] != \"centroid\"]\n",
    "centers = reducedDf[reducedDf['group'] == \"centroid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "The resulting plot will be saved as an html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = []\n",
    "xy.append(go.Scatter(x=main['component 1']\n",
    "        , y=main['component 2']\n",
    "        , mode='markers'\n",
    "        , marker=dict(size=5, color='blue')\n",
    "        , name=main_group\n",
    "        , hovertext=main['hover']\n",
    "                        ))\n",
    "\n",
    "xy.append(go.Scatter(\n",
    "      mode = 'markers',\n",
    "      x = centers['component 1'],\n",
    "      y = centers['component 2'],\n",
    "      name = \"Center\",\n",
    "      hovertext=centers['hover'],\n",
    "      marker = dict(\n",
    "        color = 'orange',\n",
    "        size = 5)))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title= \"{0} Generated Centroids\".format(N),\n",
    "    hovermode='closest',\n",
    "    xaxis=dict(title='component 1', ticklen=5, zeroline=False, gridwidth=2),\n",
    "    yaxis=dict( title='component 2', ticklen=5, gridwidth=2),\n",
    "    width=1000,\n",
    "    height=1000)\n",
    "fig = go.Figure(data=xy, layout=layout)\n",
    "fig.write_html(\"plotly_results/{0}.html\".format(center_fn))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lookalike_sample (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
